\section{Introduction}
Any biological system is characterised by interactions between components. The study of these interactions is essential to understanding the mechanisms that regulate complex diseases and to unravel the functional aspects of genetic compounds. 
In several fields of research, from social to telecommunication and biology, system interactions are increasingly represented by graphical models (\citealp{Vidal2011Complex, BAR03a, wisdomcrowds}). Generally speaking, those are defined by a set of nodes and a set of edges. Each node usually represents a specific biological component that interacts with others to perform specific functions. Edges may have several meanings, depending on the type of interactions they represent, such as similarity, causality, distance, etc. 
In the field of network theory and genetics, the nodes of a graph usually represent genes and the edges represent the interactions among nodes. Consequently, a network graph of genetic interactions is a suitable way to visualise clusters, detect modules or pathways, according to the purpose of the analysis.
Network modelling has proven to be an effective approach in computational biology due to the straightforward representation of conditional dependency between variables (\citealp{netmedicine1, netmedicine2}).
It is known that genes act in clusters and their individual effects tend to be characterised by a smaller magnitude within the system as a whole (\citealp{Michalak2008243, YiST07}). Graphical models facilitate the detection of  main genetic effects. Moreover, pathways of genes become more visible to the researcher who investigates the data, giving a more complete explanation of the biological function that the pathway itself performs.
One viable way to represent the interactions of the nodes of a graph - and consequently the  topology of the resulting network - is usually represented by the adjacency matrix $\beta = \beta_{ij}$. The values of each entry $(i,j)$ in the adjacency matrix represent the magnitude of the interaction between two nodes, whereas zeros are equivalent to absence of interaction between node $i$ and node $j$. 
Specifically to the field of computational biology, one possible way to learn the structure of genetic interactions is to analyse the expression profile of a number of genes. The task becomes challenging due to the presence of noise in the measurements, the high dimensionality of data and multicollinearity of variables. 
Despite active research in the field of high-density oligonucleotide arrays, noise still represents a consistent source of error. Any analysis subsequent to the measurement of a subset of genes should take into consideration the artifacts that are usually introduced by noise or by the computational methods performed to mitigate it (\citealp{microarray_noise, microarray_high_noise}).
In addition to the presence of noise, high dimensionality is a very common aspect of genetic data. The number of genes $p$, usually much larger than the number of individuals $n$, makes the task of discovering interactions extremely difficult. 
Without loss of generality, the problem of inferring the conditional independence between variables is equivalent to the problem of computing the sample covariance matrix of the interactions among variables. In the case of high dimensional data, as well as in a more relaxed case in which the number of individuals has a similar order of magnitude as the number of genes, the inverse of the sample covariance matrix does not exist (\citealp{Buhl93mle}). This makes the solution of the interaction problem numerically unstable and the discovered interactions unreliable. 

Finally, gene expression profiles are affected by the presence of multicollinearity (\citealp{est_multicoll, ml_multicoll}), namely two or more genes or genetic compounds can be highly correlated. Highly correlated predictor variables can give rise to non-sensical results or, specifically to regression methods, can lead to parameter estimates of incorrect magnitude and sign (\emph{harmful multicollinearity}). Moreover, the greater the number of covariates, the higher the risk of such critical scenarios (\citealp{multicollinearity_kvs}).  
A number of techniques to mitigate the problem of multicollinearity have been indicated in the literature. Regressing each covariate on the others and investigating the stability of regression models to predicting the response variable are two methods that have been denoted in (\citealp{multicollinearity_kvs}). The same line of conclusion is depicted in (\citealp{farrar1964multicollinearity}), which states that successful forecast with multicollinear variables requires both a stable dependency relationship between the response and the independent variables and stable interdependency relationships within the predictors. Collecting additional data as a solution of the multicollinearity problem is suggested in (\citealp{multicollinearity_kvs, farrar1964multicollinearity}).
The presence of multicollinearity can influence the performance of methods that rely on regression. The regression coefficient of a predictor variable's importance on the target variable has the tendency to lose precision with respect to the case in which the same genes were uncorrelated. 
From a biological perspective, it is broadly recognised that strong genetic correlations are frequent in microarray data and that, in contrast, complete independence between any two gene expression measurements is rare \citealp{Goeman2007}. Therefore, it is expected that functionally related genes are correlated to each other and might be co-expressed. This biological phenomenon can be explained by assuming the presence of high correlation for a subset of genes in the dataset under study. Moreover, as the gene sets to be tested are usually chosen on the basis of functional annotation, it should be expected that many of the tested genes might be, in fact, correlated (\citealp{genesets}).
Some regression-based methods like the one described in this paper are even more sensitive to the presence of multicollinearity as they tend to select only one or few highly correlated variables.

We propose a penalised linear regression approach that can deal with the aforementioned issues affecting genetic data. We analyse the gene expression profiles of individuals with a common trait to infer the network structure of interactions among genes. The core idea consists in reducing the number of meaningful interactions with each gene, in order to build a sparse network. Penalised linear regression (Lasso) has been investigated in seminal work reported in (\citealp{Tibshirani94regressionshrinkage, Meinshausen06highdimensional, finegold, Meinshausen_stabilityselection}), in which each variable is considered response and the remaining ones are independent covariates. In the aforementioned work, bootstrapping has been extensively used to improve the stability of the predicted interactions. Unfortunately, the nature of genetic data and the presence of highly correlated variables can play a detrimental role that affects the overall reliability of discovered interactions. Specifically, Lasso-based regression procedures are known to deal poorly with highly correlated variables since only one in a group of multi correlated covariates is selected. Bootstrapping does not seem to mitigate such a troublesome condition.

In this paper, we consider the use of Lasso penalised regression as a starting point. We subsequently rely on a permutation-based approach in order to increase the significance of predicted interactions. 

In Section \ref{approach}, we describe the method in detail. In Section \ref{results}, we measure the performance of our approach on simulated genetic networks of different size. Conclusion and future developments are drawn in Section \ref{conclusion}.

%However, it remains unclear how the three processes of differentiation, proliferation, and apoptosis in regulating stem cells collectively manage these challenging tasks.



